# 「LLMのプロンプトエンジニアリング」を読む

作成日 2025/05/27、更新日 2025/06/04

## 書籍について

『LLMのプロンプトエンジニアリング―GitHub Copilotを生んだ開発者が教える生成AIアプリケーション開発』

John Berryman、Albert Ziegler 著、服部 佑樹、佐藤 直生 訳

オライリー・ジャパン 2025年5月発行

## はじめに

本書で学べること

- I部 基礎（1章～4章）... LLMの基本的な理解、内部動作、テキスト補完エンジンとしての機能について説明
- II部 中心的なテクニック（5章～7章）... プロンプトエンジニアリングの中心的なテクニックを説明
- III部 プロンプト作成のエキスパート（8章～11章）... LLM推論のループ、パイプライン、ワークフローを組み立てる。LLMを評価するテクニック

LLMは本質的に、トレーニング中に提供されるテキストを模倣するテキスト補完エンジンにすぎない。

## 1章 プロンプトエンジニアリングの世界

1.2.1 初期の言語モデル

- seq2seqアーキテクチャ ... 再帰的ニューラルネットワーク。どんなに長いテキストでも処理できる。エンコーダーとデコーダーから成る。間の思考ベクトルが固定サイズ、「忘れて」しまうことが多い
- トランスフォーマーアーキテクチャ ... 再帰的な回路を取り除き、アテンション機構のみに依存する設計。固定された有限のシーケンスしか処理できない

1.2.2 GPTの登場

GPT = generative pre-trainned transformer 生成的事前トレーニング済みトランスフォーマー。トランスフォーマーのエンコーダーを取り除いた、デコーダーだけの構成。

## 2章 LLMを理解する

2.1 LLMとは何か

【ファインチューニング】LLMのトレーニングには膨大なデータと計算リソースが必要なため、完全にゼロからトレーニングを始めるのではなく、別のLLMのコピーから始めるのが一般的。例えばGitHub Copilotの初期バージョンは、GPT-3をベースに、GitHubに公開された大量のソースコードでファインチューニングされた

【過学習】モデルが事実やパターンを学習する代わりにテキストの一部を丸暗記してしまうこと。単なる丸暗記はLLMにとって欠陥とみなされる

LLMは統計的に最もありそうな補完を選ぶ

【ハルシネーション】事実と異なるがもっともらしく見える情報を、モデルが自信をもって生成してしまう現象

【真実バイアス】モデルは与えられたプロンプトを正しいものとみなす傾向がある

2.2 LLMが見る世界

モデルは、送信されたテキストを「トークン」と呼ばれる複数文字のチャンクに分解する。通常、トークンは3-4文字長。トークンの集合を「語彙」と呼ぶ。

【トークナイザー】送信されたテキストをトークン列に変換する。LLMはトークン列からトークン列を生成し、トークナイザーがテキストに再変換して、ユーザーに返す

2.3 1つのトークンずつ

モデルは、「複数のトークン」から「次の1つのトークン」を求め続け、必要なだけこの操作を繰り返し、単一トークンを積み重ねていく

LLMに1回処理させると、統計的に最も可能性の高い「次のトークン」が得られ、このトークンはプロンプトの末尾に付け足されて、「新しいプロンプト」を前提として、再び「次のトークン」を求める

【自己回帰 Auto-regressive】そのときの予測が次の予測に依存する仕組み

2.4 temperatureと確率

LLMは最も可能性が高いトークンだけでなく、すべてのトークンに対する確率を計算している。多くのモデルは確率情報をlogprob（トークン確率の自然対数）という形でユーザーに返すことができる。logprobが0を超えることはない。最も有力なトークンのlogprobは-2から0の間くらい

【temperature】0以上の数値で、モデルにどれくらい「創造的」になってほしいかを示す。0より大きい場合、モデルは確率的な補完を行う

temperatureが高く、上位候補のトークン同士が近いlogprobを持っているほど、2番手や3番手、4番手、5番手のトークンが選ばれる確率が上がる

2.5 トランスフォーマーアーキテクチャ

## 3章 チャット形式への移行

## 4章 LLMアプリケーションの設計

## 5章 プロンプトのコンテンツ

## 6章 プロンプトの組み立て

## 7章 モデルの制御

## 8章 会話型エージェント

## 9章 LLMワークフロー

## 10章 LLM アプリケーションの評価

## 11章 未来を見据えて
