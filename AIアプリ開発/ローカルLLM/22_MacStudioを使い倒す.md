# MacStudio512GBを使い倒す

作成日 2025/05/21

[150万円のMac Studio M3 Ultraを買ったので、使い倒す方法を考える](https://kakehashi-dev.hatenablog.com/entry/2025/05/07/090000)

## 1. コーディングの際のCopilotとして使う

コンテキスト長16384、生成長4096ぐらいの設定で32bぐらいのモデルを動かすのであれば、32GBのユニファイドメモリか24GBのVRAMで十分です。

## 2. バイブコーディングのエージェントとして使う

128kのコンテキストを扱う場合には60GB程度のメモリが必要になってきます。

アーキテクトに`QWQ:32b`、コーディングに`Qwen2.5 coder:32b`を使うアプローチであれば推論時間と実行はまだ許容範囲内ではあるのですが、商用のLLMと比較すると精度も推論速度も大きく劣ります。

## 3. Devin.aiのようなエージェントを動かす

`Qwen2.5 coder:32b`は、ollamaでも利用でき、エージェントとしてマルチターンでツールを使いながらタスクを処理させることができます。それをベースのエージェントとして利用して設計エージェントやコーディングエージェントに`DeepSeek v3 0324`などの賢いモデルを使ってじっくり設計・開発を行わせるというのは、このPCの用途としてはあっていると感じます。

## 4. ファインチューニングを行う

`Gemini 3（27B）`のようなLLMをファインチューニングする場合、LoRAのようにパラメータ量子化をせずに学習場合だと54GBのメモリが必要になります。また、長いコンテキストを扱う場合でも必要なメモリは増えるためメモリは多い方が良いです。
