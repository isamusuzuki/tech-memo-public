# モデルについて

作成日 2025/06/19

## 1. モデルの選び方

[Ollama を試すためのModelに関する知識と選び方](https://ishikawa-pro.hatenablog.com/entry/2025/02/12/103919)

> Ollama では GGUF という形式の、 Model を扱うためのファイルを利用します。GGUF はバイナリファイルで、モデルの重みや、\
> さまざまなメタデータや、量子化に関する情報を持っています。基本的には、 Ollama の公式ページに公開されている GGUF 形式の\
> Model を Pull して利用することになります。

パラメーター数

> パラメーター数は多いほど頭がいいです。しかし、パラメーター数が多ければ多いほど、必要な VRAM (GPU のメモリ) も多くなります。\
> したがって、Local LLM では自分が利用している VRAM のサイズを理解し、VRAM に乗り切るサイズの Model を使うことが重要です。

量子化

> 量子化とは、機械学習モデルの計算精度（数値のビット数）を減らして、メモリ使用量を削減し、計算速度を向上させる手法です。\
> 普通のニューラルネットワークは32ビット浮動小数点を利用しますが、量子化ではモデルの数値表現を 整数（INT8, INT4 など）\
> に変換します。そうすることでメモリ使用量を削減し、計算速度を向上させることができます。\
> また、Model を FP16（半精度浮動小数点) に変換して数値精度の削減がされたモデルもあります。 FP16 は量子化とは違い、\
> 整数化せずに計算精度を落とします。なぜ FP16 にするといいのかというと、最近のGPUには FP16 の計算に特化したコアが別途搭載されており、\
> FP16 で計算することでVRAMの使用量を削減しつつ、比較的高精度な計算を高速にすることができるからです。

## 2. モデルの違い

公開されているLLMには、いくつか違うモデルが用意されている

- pt ... pretained 事前学習済みモデル
- it ... instruction-tuned 命令チューニング済みモデル

このモデルの違いとは何か？

[What is the difference between pre-training, fine-tuning, and instruct-tuning exactly?](https://www.reddit.com/r/learnmachinelearning/comments/19f04y3/what_is_the_difference_between_pretraining/)

> **Pre-training** is the initial phase of training an LLM where it learns from a large, diverse dataset of often trillions of tokens. The goal here is to develop a broad understanding of language, context, and various types of knowledge. Pre-training is usually MASSIVELY computationally expensive and requires HUGE amounts of data. We're often talking in the millions of dollars when pre-training models. This is one of the primary reasons I am personally skeptical of the idea of open source overtaking commercial models, since most open-weight LLMs still had to come from a corporation making the initial investment in pre-training. Suffice it to say as a beginner, you will not be doing any pre-training.
>
> **Instruct-tuning** is a relatively newer concept, used in models like ChatGPT and InstructGPT, where the model is trained (or further trained) to follow instructions in prompts better. This doesn't necessarily involve adding new factual knowledge to the model; rather, it's about training the model to understand and execute given instructions more effectively. It's more about improving the model's ability to parse and respond to prompts in a way that aligns with user intentions.

理解したこと => ptは事前学習が終わった直後のモデル。初心者がptに触る必要はない。itはプロンプトによる命令に従うように訓練された後のモデル

## 3. オープンウェイトとは

[DeepSeekはオープンソースではなくオープンウェイト？ウェイトとは何か解説](https://programming.awaisora.com/a6baaa16-d924-4c0e-b589-a08135cbde14/)

> 近年、AI技術の進展に伴い、多くの機械学習モデルが公開されています。DeepSeekもその一つですが、完全なオープンソースではなく、オープンウェイトという形で公開されていることが話題になっています。
>
> 「オープンウェイト（Open Weights）」とは、機械学習モデルの学習済みウェイト（重み）のみを公開する形態を指します。一般的に、機械学習モデルは以下の3つの要素で構成されます。
>
>- モデルのコード（アルゴリズムやネットワーク構造）
>- 学習データ（トレーニングデータ）
>- 学習済みウェイト（パラメータ）
>
> オープンウェイトの場合、学習済みのウェイト（重み）のみが公開され、学習データやコードは公開されないことが一般的です。
